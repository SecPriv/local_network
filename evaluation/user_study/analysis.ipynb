{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import classes.demography, classes.scale, classes.survey, classes.evaluation\n",
    "importlib.reload(classes.demography)\n",
    "importlib.reload(classes.survey)\n",
    "importlib.reload(classes.scale)\n",
    "importlib.reload(classes.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "from classes.survey import Survey, EvaluatedSurvey, AtWorkScenarios, CafeScenarios, OutsideScenarios, GrantedScenarios, HomeScenario, LocalNetworkCheck, LocalNetworkKnowledge, NoResponse, Answer, parse_survey\n",
    "from classes.demography import Age, Gender, IT_Background, IOS_Version, Demography\n",
    "from classes.scale import ATIScale, ScaleValue\n",
    "from classes.evaluation import evaluate_answer, evaluate_surveys, get_ati_total_score, get_percentage_demographic, get_survey_time\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import Counter\n",
    "import csv\n",
    "from scipy.stats import ttest_ind, chi2_contingency, fisher_exact, chisquare\n",
    "from numpy import mean, array, var\n",
    "from math import sqrt\n",
    "import fisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_file = \"../../data/dataset/user_study/local_network_survey.csv\"\n",
    "manual_ln_label_file = \"../../data/dataset/user_study/manual_ln_label.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_manual_file(file_path: str) -> Dict[str, EvaluatedSurvey]:\n",
    "    # Parse the manual classified local network knowledge file\n",
    "    surveys = {}\n",
    "    c = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            if row[0] == 'id' or len(row[0]) == 0:\n",
    "                continue\n",
    "            survey = EvaluatedSurvey()\n",
    "            survey.survey = Survey()\n",
    "            survey.survey.prolific_id = row[0]\n",
    "            if row[2] == \"Good\":\n",
    "                survey.know_what_ln_is = True\n",
    "                c = c + 1\n",
    "            elif row[2] == \"Bad\":\n",
    "                survey.know_what_ln_is = False\n",
    "            else:\n",
    "                survey.know_what_ln_is = True # WiFi\n",
    "            \n",
    "            surveys[row[0]] = survey\n",
    "    return surveys\n",
    "\n",
    "\n",
    "def update_local_network_knowledge_from_manual_analysis(evaluated_surveys: List[EvaluatedSurvey], manual_annotations: Dict[str, EvaluatedSurvey]):\n",
    "    # Update the local network knowledge from the manual analysis\n",
    "    for evaluated_survey in evaluated_surveys:\n",
    "        if evaluated_survey.survey.prolific_id in manual_annotations:\n",
    "            evaluated_survey.know_what_ln_is = manual_annotations[evaluated_survey.survey.prolific_id].know_what_ln_is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (and not if the answer was yes or no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Use Cases                            #\n",
    "#########################################\n",
    "# \n",
    "# Evaluate use cases from Q3.3\n",
    "# \n",
    "# simply count peoples answers, i.e., how many true/false for each item separatly\n",
    "# probably just report \"don't know\" separatly\n",
    "# Report how many beleive in misconceptions or know it\n",
    "\n",
    "def evaluate_use_cases(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    questions = {}\n",
    "    for survey in evaluated_surveys:\n",
    "        if not survey.sanety_check_passed:\n",
    "            continue\n",
    "        if HomeScenario.bluetooth not in survey.survey.at_home:\n",
    "            questions[\"bluetooth_true\"] = questions.get(\"bluetooth_true\",  0) + 1\n",
    "        elif HomeScenario.bluetooth in survey.survey.at_home:\n",
    "            questions[\"bluetooth_false\"] = questions.get(\"bluetooth_false\", 0) + 1\n",
    "        if HomeScenario.internet_access not in survey.survey.at_home:\n",
    "            questions[\"internet_access_true\"] = questions.get(\"internet_access_true\", 0) + 1\n",
    "        elif HomeScenario.internet_access in survey.survey.at_home:\n",
    "            questions[\"internet_access_false\"] = questions.get(\"internet_access_false\", 0) + 1\n",
    "        if HomeScenario.smart_cast in survey.survey.at_home:\n",
    "            questions[\"smart_cast_true\"] = questions.get(\"smart_cast_true\", 0) + 1\n",
    "        elif HomeScenario.smart_cast not in survey.survey.at_home:\n",
    "            questions[\"smart_cast_false\"] = questions.get(\"smart_cast_false\",  0) + 1\n",
    "        if HomeScenario.discover_other_phones in survey.survey.at_home:\n",
    "            questions[\"discover_other_phones_true\"] = questions.get(\"discover_other_phones_true\", 0) + 1\n",
    "        elif HomeScenario.discover_other_phones not in survey.survey.at_home:\n",
    "            questions[\"discover_other_phones_false\"] = questions.get(\"discover_other_phones_false\",  0) + 1\n",
    "        if HomeScenario.none_of_above not in survey.survey.at_home:\n",
    "            questions[\"none_of_above_true\"] = questions.get(\"none_of_above_true\", 0) + 1\n",
    "        elif HomeScenario.none_of_above in survey.survey.at_home:\n",
    "            questions[\"none_of_above_false\"] = questions.get(\"none_of_above_false\", 0) + 1\n",
    "        if HomeScenario.dont_know in survey.survey.at_home:\n",
    "            questions[\"dont_know\"] = questions.get(\"dont_know\", 0) + 1\n",
    "    return questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_answers(answers: List[Answer], answer: Answer) -> Dict[str, int]:\n",
    "    result = {\n",
    "        \"count_true\": 0,\n",
    "        \"count_false\": 0,\n",
    "        \"count_dont_know\": 0\n",
    "    }\n",
    "    wrong_answer = Answer.no if answer == Answer.yes else Answer.yes\n",
    "\n",
    "    for a in answers:\n",
    "        if evaluate_answer(a, answer):\n",
    "            result[\"count_true\"] = result.get(\"count_true\", 0) + 1\n",
    "        elif evaluate_answer(a, wrong_answer):\n",
    "            result[\"count_false\"] = result.get(\"count_false\", 0) + 1\n",
    "        elif evaluate_answer(a, Answer.dont_know):\n",
    "            result[\"count_dont_know\"] = result.get(\"count_dont_know\", 0) + 1\n",
    "        else:\n",
    "            print(\"error neither true nor false nor don't know\")\n",
    "    return result\n",
    "\n",
    "def count_permission_seen(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    answers = [survey.survey.encountered_permission for survey in evaluated_surveys if survey.sanety_check_passed]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "\n",
    "def count_ln_knowledge(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    result = {\n",
    "        \"count_true\": 0,\n",
    "        \"count_false\": 0,\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if survey.know_what_ln_is:\n",
    "                result[\"count_true\"] = result.get(\"count_true\", 0) + 1\n",
    "            else:\n",
    "                result[\"count_false\"] = result.get(\"count_false\", 0) + 1\n",
    "    return result\n",
    "\n",
    "#########################################\n",
    "## Attacker Models                      #\n",
    "#########################################\n",
    "# 1) Threat of exposing offline devices (Q60)\n",
    "#\n",
    "# QUESTION: What are we doing with the \"don't know\"? It could be that\n",
    "# those people did not understand der question... When too many we need\n",
    "# think how to handle this question\n",
    "#\n",
    "# Count awarness\n",
    "def evaluate_exposing_devices(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "\n",
    "    answers = [survey.survey.granted_scenarios.exposing_devices for survey in evaluated_surveys if survey.sanety_check_passed]\n",
    "\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "\n",
    "# 2) People co-locating (Q58)\n",
    "#\n",
    "# also here probably just count true/false answers, then we report\n",
    "# how many are aware of this threat.\n",
    "#\n",
    "def evaluate_co_locating(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "\n",
    "    answers = [survey.survey.granted_scenarios.cross_user_tracking for survey in evaluated_surveys if survey.sanety_check_passed]\n",
    "\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "\n",
    "# FIXME: what to do with don't know + false\n",
    "\n",
    "# 3) Location Profiling (Q56, Q57)\n",
    "\n",
    "# check how many people know about this threat (count true/false)\n",
    "# score + if people get one of them, and none right\n",
    "def evaluate_location_profiling(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    result = {\n",
    "        \"count_true\": 0,\n",
    "     #   \"count_profiling\": 0,\n",
    "     #   \"count_location\": 0,\n",
    "        \"count_false\": 0,\n",
    "        \"count_dont_know\": 0\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.yes) and evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.yes):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.no) or evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.no):\n",
    "                result[\"count_false\"] += 1\n",
    "            elif evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.dont_know) or evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.dont_know):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "            else:\n",
    "                print(\"error neither true nor false nor don't know\")\n",
    "    return result\n",
    "\n",
    "def evaluate_location_profiling_only_location(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    answers = [survey.survey.granted_scenarios.aproximate_location for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "def evaluate_location_profiling_only_profiling(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    answers = [survey.survey.granted_scenarios.user_profiling for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "# 4) Devise Profiling (Q62, Q79)\n",
    "#\n",
    "def evaluate_device_profiling(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    result = {\n",
    "        \"count_true\": 0,\n",
    "        \"count_false\": 0,\n",
    "        \"count_dont_know\": 0\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.yes) and evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.yes):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.no) or evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.no):\n",
    "                result[\"count_false\"] += 1\n",
    "            elif evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.dont_know) or evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.dont_know):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "            else:\n",
    "                print(\"error neither true nor false nor don't know\")\n",
    "                print(survey.survey.granted_scenarios.sensitive_device)\n",
    "                print(survey.survey.granted_scenarios.exposing_devices)\n",
    "    return result\n",
    "\n",
    "def evaluate_at_least_on_threat(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    result = {\"count_true\": 0, \"count_false\": 0, \"count_dont_know\": 0}\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if (evaluate_answer(survey.survey.granted_scenarios.exposing_devices, Answer.yes) or \n",
    "                evaluate_answer(survey.survey.granted_scenarios.cross_user_tracking, Answer.yes) or \n",
    "                (evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.yes) and evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.yes)) or \n",
    "                (evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.yes) and evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.yes))):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif (evaluate_answer(survey.survey.granted_scenarios.exposing_devices, Answer.dont_know) and \n",
    "                evaluate_answer(survey.survey.granted_scenarios.cross_user_tracking, Answer.dont_know) and \n",
    "                (evaluate_answer(survey.survey.granted_scenarios.aproximate_location, Answer.dont_know) and evaluate_answer(survey.survey.granted_scenarios.user_profiling, Answer.dont_know)) and \n",
    "                (evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.dont_know) and evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.dont_know))):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "            else:\n",
    "                result[\"count_false\"] += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate_device_profiling_stat_test(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    result = evaluate_device_profiling(evaluated_surveys)\n",
    "    result[\"count_dont_know\"] = result[\"count_dont_know\"] + result[\"count_sensitive\"]\n",
    "    result[\"count_dont_know\"] = result[\"count_dont_know\"] + result[\"count_device\"]\n",
    "    del result[\"count_device\"]\n",
    "    del result[\"count_sensitive\"]\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_device_profiling_only_sensitive(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    answers = [survey.survey.granted_scenarios.sensitive_device for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.granted_scenarios.detect_other_devices, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "def evaluate_device_profiling_only_device(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, int]:\n",
    "    answers = [survey.survey.granted_scenarios.detect_other_devices for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.granted_scenarios.sensitive_device, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.yes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Concepts                             #\n",
    "#########################################\n",
    "#\n",
    "\n",
    "# 1) Proximity does not imply local network (Q65, Q66) \n",
    "#\n",
    "\n",
    "def evaluate_proximity_v2(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    result = {\n",
    "        \"count_true\": 0,\n",
    "        \"count_false\": 0,\n",
    "        \"count_dont_know\": 0,\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if evaluate_answer(survey.survey.outside_scenarios.connect_smart_tv, Answer.no) and evaluate_answer(survey.survey.outside_scenarios.other_mobile_phones, Answer.no):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif evaluate_answer(survey.survey.outside_scenarios.connect_smart_tv, Answer.yes) or evaluate_answer(survey.survey.outside_scenarios.other_mobile_phones, Answer.yes):\n",
    "                result[\"count_false\"] += 1\n",
    "            elif evaluate_answer(survey.survey.outside_scenarios.connect_smart_tv, Answer.dont_know) or evaluate_answer(survey.survey.outside_scenarios.other_mobile_phones, Answer.dont_know):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def evaluate_proximity_v2_only_smart_tv(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.outside_scenarios.connect_smart_tv for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.outside_scenarios.other_mobile_phones, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.no)\n",
    "\n",
    "def evaluate_proximity_v2_only_mobile_phones(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.outside_scenarios.other_mobile_phones for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.outside_scenarios.connect_smart_tv, Answer.dont_know)]\n",
    "    return count_answers(answers, Answer.no)\n",
    "\n",
    "# 2) Boundries (Q67\n",
    "#\n",
    "# just count how many people get question right/wrong\n",
    "def evaluate_boundries(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "\n",
    "    answers = [survey.survey.outside_scenarios.connect_smart_tv_at_home for survey in evaluated_surveys if survey.sanety_check_passed]\n",
    "\n",
    "    return count_answers(answers, Answer.no)\n",
    "\n",
    "\n",
    "# 3) Transitivity, Taking the Permission with You (Q68, Q69)\n",
    "#\n",
    "# we use HomeScenario.smart_cast as the baseline\n",
    "def evaluate_transitivity_1(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    result = { \n",
    "        \"count_true\": 0, # if baseline right cafe and work right\n",
    "        \"count_false\": 0, # if baseline right cafe and work wrong\n",
    "        \"count_dont_know\": 0\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.smart_cast not in survey.survey.at_home:\n",
    "                continue\n",
    "           \n",
    "            if evaluate_answer(survey.survey.cafe_scenarios.connect_smart_tv, Answer.yes) and evaluate_answer(survey.survey.at_work_scenarios.connect_printer, Answer.yes):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif evaluate_answer(survey.survey.cafe_scenarios.connect_smart_tv, Answer.no) or evaluate_answer(survey.survey.at_work_scenarios.connect_printer, Answer.no):\n",
    "                result[\"count_false\"] += 1\n",
    "\n",
    "            elif evaluate_answer(survey.survey.cafe_scenarios.connect_smart_tv, Answer.dont_know) or evaluate_answer(survey.survey.at_work_scenarios.connect_printer, Answer.dont_know):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "            else:\n",
    "                print(\"error neither true nor false\")\n",
    "                print(survey.survey.cafe_scenarios.connect_smart_tv)\n",
    "                print(survey.survey.at_work_scenarios.connect_printer)\n",
    "    return result\n",
    "\n",
    "def get_transitivity_1_false(evaluated_surveys: List[EvaluatedSurvey]) -> List[str]:\n",
    "    result = []\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.smart_cast not in survey.survey.at_home:\n",
    "                continue\n",
    "            \n",
    "            if evaluate_answer(survey.survey.cafe_scenarios.connect_smart_tv, Answer.no) and evaluate_answer(survey.survey.at_work_scenarios.connect_printer, Answer.no):\n",
    "                result.append(survey.survey.prolific_id)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_transitivity_1_base(evaluated_surveys: List[EvaluatedSurvey]) -> List[str]:\n",
    "    result = {\"count_true\": 0, \"count_false\": 0, \"count_dont_know\": 0}\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.dont_know in survey.survey.at_home:\n",
    "                result[\"count_dont_know\"] = result.get(\"count_dont_know\", 0) + 1\n",
    "            elif HomeScenario.smart_cast in survey.survey.at_home:\n",
    "                result[\"count_true\"] = result.get(\"count_true\", 0) + 1\n",
    "            elif HomeScenario.smart_cast not in survey.survey.at_home:\n",
    "                result[\"count_false\"] = result.get(\"count_false\", 0) + 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "def evaluate_transitivity_1_only_cafe(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.cafe_scenarios.connect_smart_tv for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.at_work_scenarios.connect_printer, Answer.dont_know) and HomeScenario.discover_other_phones in survey.survey.at_home]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "def evaluate_transitivity_1_only_work(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.at_work_scenarios.connect_printer for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.cafe_scenarios.connect_smart_tv, Answer.dont_know) and HomeScenario.discover_other_phones in survey.survey.at_home]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "\n",
    "# 4) Transivity 2 (Q70, Q77) - Baseline HomeScenario.discover_other_phones\n",
    "def get_transitivity_2_base(evaluated_surveys: List[EvaluatedSurvey]) -> List[str]:\n",
    "    result = {\"count_true\": 0, \"count_false\": 0, \"count_dont_know\": 0}\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.dont_know in survey.survey.at_home:\n",
    "                result[\"count_dont_know\"] = result.get(\"count_dont_know\", 0) + 1\n",
    "            elif HomeScenario.discover_other_phones in survey.survey.at_home:\n",
    "                result[\"count_true\"] = result.get(\"count_true\", 0) + 1\n",
    "            elif HomeScenario.discover_other_phones not in survey.survey.at_home:\n",
    "                result[\"count_false\"] = result.get(\"count_false\", 0) + 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "def evaluate_transitivity_2(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    result = { \n",
    "        \"count_true\": 0, # if baseline right cafe and work right\n",
    "        \"count_false\": 0, # if baseline right cafe and work wrong\n",
    "        \"count_dont_know\": 0\n",
    "    }\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.discover_other_phones not in survey.survey.at_home:\n",
    "                continue\n",
    "            if evaluate_answer(survey.survey.cafe_scenarios.other_mobile_phones, Answer.yes) and evaluate_answer(survey.survey.at_work_scenarios.other_mobile_phones, Answer.yes):\n",
    "                result[\"count_true\"] += 1\n",
    "            elif evaluate_answer(survey.survey.cafe_scenarios.other_mobile_phones, Answer.no) or evaluate_answer(survey.survey.at_work_scenarios.other_mobile_phones, Answer.no):\n",
    "                result[\"count_false\"] += 1\n",
    "            elif evaluate_answer(survey.survey.cafe_scenarios.other_mobile_phones, Answer.dont_know) or evaluate_answer(survey.survey.at_work_scenarios.other_mobile_phones, Answer.dont_know):\n",
    "                result[\"count_dont_know\"] += 1\n",
    "            else:\n",
    "                print(\"error neither true nor false\")\n",
    "                print(survey.survey.cafe_scenarios.connect_smart_tv)\n",
    "                print(survey.survey.at_work_scenarios.connect_printer)\n",
    "    return result\n",
    "\n",
    "def get_transitivity_2_false(evaluated_surveys: List[EvaluatedSurvey]) -> List[str]:\n",
    "    result = []\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            if HomeScenario.discover_other_phones not in survey.survey.at_home:\n",
    "                continue\n",
    "            if evaluate_answer(survey.survey.cafe_scenarios.other_mobile_phones, Answer.no) and evaluate_answer(survey.survey.at_work_scenarios.other_mobile_phones, Answer.no):\n",
    "                result.append(survey.survey.prolific_id)\n",
    "    return result\n",
    "\n",
    "def evaluate_transitivity_2_only_cafe(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.cafe_scenarios.other_mobile_phones for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.at_work_scenarios.other_mobile_phones, Answer.dont_know) and HomeScenario.discover_other_phones  in survey.survey.at_home]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "def evaluate_transitivity_2_only_work(evaluated_surveys: List[EvaluatedSurvey]) -> Dict[str, str]:\n",
    "    answers = [survey.survey.at_work_scenarios.other_mobile_phones for survey in evaluated_surveys if survey.sanety_check_passed and evaluate_answer(survey.survey.cafe_scenarios.other_mobile_phones, Answer.dont_know) and HomeScenario.discover_other_phones  in survey.survey.at_home]\n",
    "    return count_answers(answers, Answer.yes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "## Dummy Questions                      #\n",
    "#########################################\n",
    "#\n",
    "# Ignore these questions: Q54, Q59, Q75\n",
    "\n",
    "\n",
    "#########################################\n",
    "## Misconceptions                       #\n",
    "#########################################\n",
    "#\n",
    "# These are misconceptions we found online Q61\n",
    "#\n",
    "\n",
    "def evaluate_misconceptions(evaluated_surveys: List[EvaluatedSurvey]) ->  Dict[str, int]:\n",
    "    result = {\"wifi_password\": 0,  \"visible_phone\": 0, \"internet_access\": 0, \"bluetooth\": 0, \"any_misconception\": 0}\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed:\n",
    "            has_misconception = False\n",
    "            if evaluate_answer(survey.survey.granted_scenarios.read_wifi_password, Answer.yes):\n",
    "                result[\"wifi_password\"] = result.get(\"wifi_password\", 0)+ 1\n",
    "                has_misconception = True\n",
    "            if evaluate_answer(survey.survey.granted_scenarios.phone_become_visible, Answer.yes):\n",
    "                result[\"visible_phone\"] = result.get(\"visible_phone\", 0)+ 1\n",
    "                has_misconception = True\n",
    "            if HomeScenario.internet_access in survey.survey.at_home:\n",
    "                result[\"internet_access\"] = result.get(\"internet_access\", 0)+ 1\n",
    "                has_misconception = True\n",
    "            if HomeScenario.bluetooth in survey.survey.at_home:\n",
    "                result[\"bluetooth\"] = result.get(\"bluetooth\", 0) + 1\n",
    "                has_misconception = True\n",
    "            if has_misconception:\n",
    "                result[\"any_misconception\"] = result.get(\"any_misconception\", 0) + 1\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_responses(evaluated_surveys: List[EvaluatedSurvey]) -> int:\n",
    "    return len([survey for survey in evaluated_surveys if survey.sanety_check_passed])\n",
    "\n",
    "def get_formatted_dict(result: Dict[str, int], total_number) -> Dict[str, str]:\n",
    "    formatted_result = {}\n",
    "    for key, value in result.items():\n",
    "        formatted_result[key] = f\"{value} ({value/total_number*100:.2f}%)\"\n",
    "    return formatted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_network_score(evaluated_suverys: List[EvaluatedSurvey]) -> List[int]:\n",
    "    result = []\n",
    "    for survey in evaluated_suverys:\n",
    "        if survey.sanety_check_passed:\n",
    "            result.append(survey.ln_count_score if survey.ln_count_score >= 0 else 0)\n",
    "    return result\n",
    "\n",
    "def perform_p_test(evaluated_surveys: List[EvaluatedSurvey]):\n",
    "    knows_local_network = []\n",
    "    does_not_know_local_network = []\n",
    "    for survey in evaluated_surveys:\n",
    "        if survey.sanety_check_passed: #and survey.ln_count_score >= 0:\n",
    "            score = survey.ln_count_score if survey.ln_count_score >= 0 else 0\n",
    "            if survey.know_what_ln_is is True:\n",
    "                knows_local_network.append(score)\n",
    "                if survey.ln_count_score == -1:\n",
    "                    print(survey.survey.prolific_id)\n",
    "            elif survey.know_what_ln_is is False:\n",
    "                does_not_know_local_network.append(score)\n",
    "    print(statistics.mean(knows_local_network))\n",
    "    print(statistics.mean(does_not_know_local_network))\n",
    "\n",
    "    print(statistics.stdev(knows_local_network))\n",
    "    print(statistics.stdev(does_not_know_local_network))\n",
    "\n",
    "    print(statistics.median(knows_local_network))\n",
    "    print(statistics.median(does_not_know_local_network))\n",
    "\n",
    "    return ttest_ind(knows_local_network, does_not_know_local_network, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate Cohen's d for independent samples\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "# Compute Cramér's V\n",
    "def cramers_v(chi2, N, n, m): # Chi-square statistic, Total number of observations, Number of rows, Number of columns\n",
    "    return sqrt(chi2 / (N * min(n-1, m-1)))\n",
    "\n",
    "\n",
    "def chi_square_test(result_1, result_2):\n",
    "    chi2, p, dof, expected = chi2_contingency([list(result_1.values()), list(result_2.values())])\n",
    "\n",
    "    print(\"Chi-square statistic:\", chi2)\n",
    "    print(\"p-value:\", p)    \n",
    "    print(\"Degrees of freedom:\", dof)\n",
    "    print(\"Expected frequencies:\")\n",
    "    print(expected)\n",
    "    # Calculate Cramér's V\n",
    "    n = 0\n",
    "    for x in list(result_1.values()) + list(result_2.values()):\n",
    "        n = n + x\n",
    "    print(\"phi\", sqrt(chi2/n ))\n",
    "    print(f\"Cramér's V: {cramers_v(chi2, n, 2, len(result_1))}\") # effect size\n",
    "    return {\"chi^2\": chi2, \"p-value\": p, \"dof\": dof, \"phi\": sqrt(chi2/n ) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_rows_and_index(evaluated_surveys: List[EvaluatedSurvey], valid_responses):\n",
    "    index = []\n",
    "    results = []\n",
    "    results.append(get_formatted_dict(evaluate_exposing_devices(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Exposing Devices\")\n",
    "    results.append(get_formatted_dict(evaluate_co_locating(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Co-locating\")\n",
    "    results.append(get_formatted_dict(evaluate_location_profiling(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Location Profiling\")\n",
    "    results.append(get_formatted_dict(evaluate_location_profiling_only_location(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Location Profiling-Only Location\")\n",
    "    results.append(get_formatted_dict(evaluate_location_profiling_only_profiling(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Location Profiling-Only Profiling\")\n",
    "    results.append(get_formatted_dict(evaluate_device_profiling(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Device Profiling\")\n",
    "    results.append(get_formatted_dict(evaluate_device_profiling_only_sensitive(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Device Profiling-Only Sensitive\")\n",
    "    results.append(get_formatted_dict(evaluate_device_profiling_only_device(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Device Profiling-Only Device\")\n",
    "    results.append(get_formatted_dict(evaluate_at_least_on_threat(evaluated_surveys), valid_responses))\n",
    "    index.append(\"At Least One Threat\")\n",
    "\n",
    "\n",
    "    results.append(get_formatted_dict(evaluate_proximity_v2(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Proximity\")\n",
    "    results.append(get_formatted_dict(evaluate_proximity_v2_only_smart_tv(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Proximity-Only Smart TV\")\n",
    "    results.append(get_formatted_dict(evaluate_proximity_v2_only_mobile_phones(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Proximity-Only Mobile Phones\")\n",
    "    results.append(get_formatted_dict(evaluate_boundries(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Boundries\")\n",
    "    results.append(get_formatted_dict(get_transitivity_1_base(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Transitivity 1 Base\")\n",
    "    transitivity_1_count = 0\n",
    "    for value in evaluate_transitivity_1(evaluated_surveys).values():\n",
    "        transitivity_1_count += value\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_1(evaluated_surveys), transitivity_1_count ))\n",
    "    index.append(\"Transitivity 1\")\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_1_only_cafe(evaluated_surveys), transitivity_1_count))\n",
    "    index.append(\"Transitivity 1-Only Cafe\")\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_1_only_work(evaluated_surveys), transitivity_1_count))\n",
    "    index.append(\"Transitivity 1-Only Work\")\n",
    "    results.append(get_formatted_dict(get_transitivity_2_base(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Transitivity 2 Base\")\n",
    "    transitivity_2_count = 0\n",
    "    for value in evaluate_transitivity_1(evaluated_surveys).values():\n",
    "        transitivity_2_count += value\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_2(evaluated_surveys), transitivity_2_count))\n",
    "    index.append(\"Transitivity 2\")\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_2_only_cafe(evaluated_surveys), transitivity_2_count))\n",
    "    index.append(\"Transitivity 2-Only Cafe\")\n",
    "    results.append(get_formatted_dict(evaluate_transitivity_2_only_work(evaluated_surveys), transitivity_2_count))\n",
    "    index.append(\"Transitivity 2-Only Work\")\n",
    "\n",
    "    results.append(get_formatted_dict(evaluate_misconceptions(evaluated_surveys), valid_responses))\n",
    "    index.append(\"Misconceptions\")\n",
    "\n",
    "    return results, index\n",
    "\n",
    "\n",
    "def get_result_rows_chi_square(know_ln_surveys: List[EvaluatedSurvey], do_not_know_ln_survey: List[EvaluatedSurvey]):\n",
    "    results = []\n",
    "    results.append(chi_square_test(evaluate_exposing_devices(know_ln_surveys), evaluate_exposing_devices(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_co_locating(know_ln_surveys), evaluate_co_locating(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_location_profiling(know_ln_surveys), evaluate_location_profiling(do_not_know_ln_survey)))\n",
    "    results.append({})\n",
    "    results.append({})\n",
    "    results.append(chi_square_test(evaluate_device_profiling(know_ln_surveys), evaluate_device_profiling(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_device_profiling_only_sensitive(know_ln_surveys), evaluate_device_profiling_only_sensitive(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_device_profiling_only_device(know_ln_surveys), evaluate_device_profiling_only_device(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_at_least_on_threat(know_ln_surveys), evaluate_at_least_on_threat(do_not_know_ln_survey)))\n",
    "\n",
    "    results.append(chi_square_test(evaluate_proximity_v2(know_ln_surveys), evaluate_proximity_v2(do_not_know_ln_survey)))\n",
    "    results.append({})\n",
    "    results.append({})\n",
    "    results.append(chi_square_test(evaluate_boundries(know_ln_surveys), evaluate_boundries(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(get_transitivity_1_base(know_ln_surveys), get_transitivity_1_base(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_1(know_ln_surveys), evaluate_transitivity_1(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_1_only_cafe(know_ln_surveys), evaluate_transitivity_1_only_cafe(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_1_only_work(know_ln_surveys), evaluate_transitivity_1_only_work(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(get_transitivity_2_base(know_ln_surveys), get_transitivity_2_base(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_2(know_ln_surveys), evaluate_transitivity_2(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_2_only_cafe(know_ln_surveys), evaluate_transitivity_2_only_cafe(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_transitivity_2_only_work(know_ln_surveys), evaluate_transitivity_2_only_work(do_not_know_ln_survey)))\n",
    "    results.append(chi_square_test(evaluate_misconceptions(know_ln_surveys), evaluate_misconceptions(do_not_know_ln_survey)))\n",
    "    return results\n",
    "\n",
    "def get_results_csv(evaluated_suverys: List[EvaluatedSurvey], valid_responses, file_name: str):\n",
    "    results, index = get_results_rows_and_index(evaluated_suverys, valid_responses)\n",
    "    df = pd.DataFrame(results, index=index)\n",
    "    df.to_csv(file_name)\n",
    "\n",
    "\n",
    "def append_to_keys(result, append):\n",
    "    to_return = {}\n",
    "    for key, value in result.items():\n",
    "        to_return[key + append] = value\n",
    "    return to_return\n",
    "\n",
    "def append_all_to_keys(result, append):\n",
    "    to_return = []\n",
    "    for r in result:\n",
    "        to_return.append(append_to_keys(r, append))\n",
    "    return to_return\n",
    "\n",
    "def get_results_csv_with_x_squared(know_ln_surveys: List[EvaluatedSurvey], do_not_know_ln_survey: List[EvaluatedSurvey], file_name: str):\n",
    "    results_ln, index = get_results_rows_and_index(know_ln_surveys, len(know_ln_surveys))\n",
    "    results_nln, _ = get_results_rows_and_index(do_not_know_ln_survey, len(do_not_know_ln_survey))\n",
    "    results_ln = append_all_to_keys(results_ln, \"_know_ln\")\n",
    "    results_nln = append_all_to_keys(results_nln, \"_do_not_know\")\n",
    "    results_chi_square = get_result_rows_chi_square(know_ln_surveys, do_not_know_ln_survey)\n",
    "    df_1 = pd.DataFrame(results_ln, index=index)\n",
    "    df_2 = pd.DataFrame(results_nln, index=index)\n",
    "    df_3 = pd.DataFrame(results_chi_square, index=index)\n",
    "    df = pd.concat([df_1, df_2, df_3], axis=1)\n",
    "    df.to_csv(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "survey_results = parse_survey(survey_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_decision = parse_manual_file(manual_ln_label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_suverys = evaluate_surveys(survey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_local_network_knowledge_from_manual_analysis(evaluated_suverys, manual_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_suverys_know_what_ln_is = [survey for survey in evaluated_suverys if survey.know_what_ln_is is True and survey.sanety_check_passed]\n",
    "evaluated_suverys_do_not_know_what_ln_is = [survey for survey in evaluated_suverys if survey.know_what_ln_is is False and survey.sanety_check_passed]\n",
    "evaluated_suverys_techical_background = [survey for survey in evaluated_suverys if survey.has_it_background is True and survey.sanety_check_passed]\n",
    "evaluated_suverys_no_techical_background = [survey for survey in evaluated_suverys if survey.has_it_background is False and survey.sanety_check_passed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for e in evaluated_suverys:\n",
    "    if e.sanety_check_passed and not e.know_what_ln_is:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_p_test(evaluated_suverys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohend(get_local_network_score(evaluated_suverys_know_what_ln_is), get_local_network_score(evaluated_suverys_do_not_know_what_ln_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_responses = get_valid_responses(evaluated_suverys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_survey_time(evaluated_suverys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ati_total_score(evaluated_suverys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_percentage_demographic(evaluated_suverys, number_of_results=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_formatted_dict(count_permission_seen(evaluated_suverys), valid_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evaluated_suverys_techical_background)/valid_responses*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Use Cases                            #\n",
    "#########################################\n",
    "# \n",
    "# Evaluate use cases from Q3.3\n",
    "# \n",
    "\n",
    "print(get_formatted_dict(evaluate_use_cases(evaluated_suverys), valid_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Attacker Models                      #\n",
    "#########################################\n",
    "# \n",
    "# 1) Threat of exposing offline devices (Q60)\n",
    "#\n",
    "\n",
    "# \n",
    "print(\"exposing devices\")\n",
    "print(get_formatted_dict(evaluate_exposing_devices(evaluated_suverys), valid_responses))\n",
    "\n",
    "# 2) People co-locating (Q58)\n",
    "#\n",
    "\n",
    "# how many are aware of this threat.\n",
    "#\n",
    "print(\"People co-locating\")\n",
    "print(get_formatted_dict(evaluate_co_locating(evaluated_suverys), valid_responses))\n",
    "\n",
    "# 3) Location Profiling (Q56, Q57)\n",
    "#\n",
    "\n",
    "#\n",
    "\n",
    "print(\"location\")\n",
    "print(get_formatted_dict(evaluate_location_profiling(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_location_profiling_only_location(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_location_profiling_only_profiling(evaluated_suverys), valid_responses))\n",
    "\n",
    "# 4) Devise Profiling (Q62, Q79)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "print(\"device\")\n",
    "print(get_formatted_dict(evaluate_device_profiling(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_device_profiling_only_sensitive(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_device_profiling_only_device(evaluated_suverys), valid_responses))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# At least one threat\n",
    "print(\"at least on threat\")\n",
    "print(get_formatted_dict(evaluate_at_least_on_threat(evaluated_suverys), valid_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "## Concepts                             #\n",
    "#########################################\n",
    "#\n",
    "# 1) Proximity does not imply local network (Q65, Q66) \n",
    "#\n",
    "\n",
    "print(\"proximity\")\n",
    "print(get_formatted_dict(evaluate_proximity_v2(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_proximity_v2_only_smart_tv(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_proximity_v2_only_mobile_phones(evaluated_suverys), valid_responses))\n",
    "\n",
    "# 2) Boundries (Q67\n",
    "#\n",
    "\n",
    "print(\"boundries\")\n",
    "print(get_formatted_dict(evaluate_boundries(evaluated_suverys), valid_responses))\n",
    "\n",
    "# 3) Transitivity, Taking the Permission with You (Q68, Q69)\n",
    "#\n",
    "print(\"transitivity - 1\")\n",
    "print(get_formatted_dict(get_transitivity_1_base(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_1(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_1_only_cafe(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_1_only_work(evaluated_suverys), valid_responses))\n",
    "\n",
    "\n",
    "# 4) Transitivity 2 - (Q70, Q77)\n",
    "print(\"transitivity - 2\")\n",
    "print(get_formatted_dict(get_transitivity_2_base(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_2(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_2_only_cafe(evaluated_suverys), valid_responses))\n",
    "print(get_formatted_dict(evaluate_transitivity_2_only_work(evaluated_suverys), valid_responses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(get_transitivity_1_false(evaluated_suverys)).intersection(get_transitivity_2_false(evaluated_suverys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#########################################\n",
    "## Misconceptions                       #\n",
    "#########################################\n",
    "#\n",
    "# These are misconceptions we found online Q61\n",
    "#\n",
    "\n",
    "print(get_formatted_dict(evaluate_misconceptions(evaluated_suverys), valid_responses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tech background better local nework understanding?\n",
    "print(get_formatted_dict(count_ln_knowledge(evaluated_suverys_techical_background), len(evaluated_suverys_techical_background)))\n",
    "print(get_formatted_dict(count_ln_knowledge(evaluated_suverys_no_techical_background), len(evaluated_suverys_no_techical_background)))\n",
    "chi_square_test(count_ln_knowledge(evaluated_suverys_techical_background), count_ln_knowledge(evaluated_suverys_no_techical_background))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - better exposing devices?\n",
    "\n",
    "print(get_formatted_dict(evaluate_exposing_devices(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_exposing_devices(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(evaluate_exposing_devices(evaluated_suverys_know_what_ln_is), evaluate_exposing_devices(evaluated_suverys_do_not_know_what_ln_is))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - better device profiling?\n",
    "\n",
    "print(get_formatted_dict(evaluate_device_profiling(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_device_profiling(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(evaluate_device_profiling(evaluated_suverys_know_what_ln_is), evaluate_device_profiling(evaluated_suverys_do_not_know_what_ln_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - better co locationg understanding?\n",
    "\n",
    "print(get_formatted_dict(evaluate_co_locating(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_co_locating(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(evaluate_co_locating(evaluated_suverys_know_what_ln_is), evaluate_co_locating(evaluated_suverys_do_not_know_what_ln_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - better location profiling understanding?\n",
    "\n",
    "print(get_formatted_dict(evaluate_location_profiling(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_location_profiling(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "\n",
    "chi_square_test(evaluate_location_profiling(evaluated_suverys_know_what_ln_is), evaluate_location_profiling(evaluated_suverys_do_not_know_what_ln_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - are aware of at least one threat\n",
    "print(get_formatted_dict(evaluate_at_least_on_threat(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_at_least_on_threat(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "\n",
    "chi_square_test(evaluate_at_least_on_threat(evaluated_suverys_know_what_ln_is), evaluate_at_least_on_threat(evaluated_suverys_do_not_know_what_ln_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - are aware of proximity\n",
    "\n",
    "print(get_formatted_dict(evaluate_proximity_v2(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_proximity_v2(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "\n",
    "chi_square_test(evaluate_proximity_v2(evaluated_suverys_know_what_ln_is), evaluate_proximity_v2(evaluated_suverys_do_not_know_what_ln_is))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - are aware of network boundaries\n",
    "\n",
    "print(get_formatted_dict(evaluate_boundries(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(evaluate_boundries(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(evaluate_boundries(evaluated_suverys_know_what_ln_is), evaluate_boundries(evaluated_suverys_do_not_know_what_ln_is))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - are aware of transivity\n",
    "\n",
    "print(get_formatted_dict(get_transitivity_1_base(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(get_transitivity_1_base(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(get_transitivity_1_base(evaluated_suverys_know_what_ln_is), get_transitivity_1_base(evaluated_suverys_do_not_know_what_ln_is))\n",
    "print(\"-------\")\n",
    "\n",
    "\n",
    "eval1_ln = evaluate_transitivity_1(evaluated_suverys_know_what_ln_is)\n",
    "eval1_nln = evaluate_transitivity_1(evaluated_suverys_do_not_know_what_ln_is)\n",
    "\n",
    "print(get_formatted_dict(eval1_ln, len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(eval1_nln, len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "\n",
    "chi_square_test(eval1_ln, eval1_nln)\n",
    "print(\"-------\")\n",
    "\n",
    "\n",
    "\n",
    "# If ln understanding - are aware of transivity 2\n",
    "\n",
    "print(\"transitivity_2 - base\")\n",
    "print(get_formatted_dict(get_transitivity_2_base(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "print(get_formatted_dict(get_transitivity_2_base(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(get_transitivity_2_base(evaluated_suverys_know_what_ln_is), get_transitivity_2_base(evaluated_suverys_do_not_know_what_ln_is))\n",
    "print(\"-------\")\n",
    "\n",
    "eval2_ln = evaluate_transitivity_2(evaluated_suverys_know_what_ln_is)\n",
    "eval2_nln = evaluate_transitivity_2(evaluated_suverys_do_not_know_what_ln_is)\n",
    "\n",
    "print(get_formatted_dict(eval2_ln, 15+ 29 + 16)) # right base question ln \n",
    "print(get_formatted_dict(eval2_nln, 11 + 26 + 12)) # right base question nln\n",
    "\n",
    "chi_square_test(eval2_ln, eval2_nln)\n",
    "print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ln understanding - are aware of misconceptions\n",
    "\n",
    "print(get_formatted_dict(evaluate_misconceptions(evaluated_suverys_know_what_ln_is), len(evaluated_suverys_know_what_ln_is)))\n",
    "\n",
    "print(get_formatted_dict(evaluate_misconceptions(evaluated_suverys_do_not_know_what_ln_is), len(evaluated_suverys_do_not_know_what_ln_is)))\n",
    "chi_square_test(evaluate_misconceptions(evaluated_suverys_know_what_ln_is), evaluate_misconceptions(evaluated_suverys_do_not_know_what_ln_is))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_csv(evaluated_suverys, valid_responses, \"evaluate_survey_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_csv_with_x_squared(evaluated_suverys_know_what_ln_is, evaluated_suverys_do_not_know_what_ln_is, \"evaluate_survey_compare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
